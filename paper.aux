\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Motivation}{1}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}System Architecture}{2}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Ingestion Layer}{2}{subsection.3.1}\protected@file@percent }
\@writefile{lol}{\contentsline {lstlisting}{\numberline {1}Loop where Chunks are Processed and Inserted into DB}{2}{lstlisting.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Storage Layer}{2}{subsection.3.2}\protected@file@percent }
\@writefile{lol}{\contentsline {lstlisting}{\numberline {2}Cosine-Similarity Search SQL}{3}{lstlisting.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Generation Layer}{3}{subsection.3.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Benchmark Results}{3}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Ingestion Benchmark Results}{3}{subsection.4.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Ingestion metrics illustrating sublinear scalability, and therefore the efficiency of the batch-processing relative to setup-overhead.}}{3}{table.1}\protected@file@percent }
\newlabel{tab:ingestion}{{1}{3}{Ingestion metrics illustrating sublinear scalability, and therefore the efficiency of the batch-processing relative to setup-overhead}{table.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Retrieval and Generation Latency Benchmark Results}{3}{subsection.4.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Latency Breakdown. Total time includes all of the overheads not mentioned (network, serialization).}}{4}{table.2}\protected@file@percent }
\newlabel{tab:latency}{{2}{4}{Latency Breakdown. Total time includes all of the overheads not mentioned (network, serialization)}{table.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Generation Throughput Benchmark Results}{4}{subsection.4.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Token generation throughput (Tokens/Second) for three example test queries.}}{4}{figure.1}\protected@file@percent }
\newlabel{fig:throughput}{{1}{4}{Token generation throughput (Tokens/Second) for three example test queries}{figure.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusion}{4}{section.5}\protected@file@percent }
\gdef \@abspage@last{4}
